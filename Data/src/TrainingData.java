import Utils.Utils;
import Utils.PriorityQueue;
import java.io.*;
import java.util.HashSet;
import java.util.List;
import java.util.Random;
import java.util.Set;

class TrainingData {
    private int numThreads;
    private int fileSize;
    private String datasetDir;
    private double trainRatio;
    private double testRatio;
    private String dataType;

    TrainingData(int numThreads, int fileSize, String pathToDataset, double sampleRatio, String dataType) {
        this.fileSize = fileSize;
        this.numThreads = numThreads;
        this.datasetDir = pathToDataset;
        this.trainRatio = sampleRatio;
        this.testRatio = sampleRatio / 5;
        this.dataType = dataType;
    }
    void generateTripletSamples() throws InterruptedException, IOException {
        TripletDataThread[] tdT = new TripletDataThread[numThreads];
        for(int i = 0; i < numThreads; i++) {
            tdT[i] = new TripletDataThread(i,datasetDir, trainRatio, dataType, fileSize);
            tdT[i].start();
        }
        for(int i = 0; i < numThreads; i++) {
            tdT[i].join();
        }

        File file;
        String line;
        BufferedWriter trainWriterT = new BufferedWriter(new FileWriter(new File("./data/trainingData-triplet")));
        for(int i = 0; i < numThreads; i++) {
            file = new File("./data/trainingData-triplet-" + String.valueOf(i));
            if(!file.exists()) break;
            BufferedReader trainReader = new BufferedReader(new FileReader(file));
            if(i != 0) trainReader.readLine();
            while((line = trainReader.readLine()) != null) {
                trainWriterT.write(line + "\n");
            }
            trainReader.close();
            file.delete();
        }
        trainWriterT.flush(); trainWriterT.close();
        System.out.println("subfiles generated");
    }

    void generateSiameseSamples() throws InterruptedException, IOException {
        SiameseDataThread[] sdT = new SiameseDataThread[numThreads];
        for(int i = 0; i < numThreads; i++) {
            sdT[i] = new SiameseDataThread(i, datasetDir, trainRatio, dataType, fileSize);
            sdT[i].start();
        }
        for(int i = 0; i < numThreads; i++) {
            sdT[i].join();
        }

        BufferedWriter trainWriter = new BufferedWriter(new FileWriter(new File("./data/trainingData-siamese")));
        String line;
        File file;
        for(int i = 0; i < numThreads; i++) {
            file = new File("./data/trainingData-siamese-" + String.valueOf(i));
            if(!file.exists()) break;
            BufferedReader trainReader = new BufferedReader(new FileReader(file));
            if(i != 0) trainReader.readLine();
            while((line = trainReader.readLine()) != null) {
                trainWriter.write(line + "\n");
            }
            trainReader.close();
            file.delete();
        }
        trainWriter.flush(); trainWriter.close();

        System.out.println("subfiles generated");
    }
    void clean() throws IOException {
        this.combineFiles();
    }

    void combineFiles() throws IOException {
        String line;
        File file;
        //combine original data separated for different threads
        BufferedWriter bwOfThread = new BufferedWriter((new FileWriter(new File("./data/originalVectors"))));
        for(int i = 0; i < numThreads; i++) {
            file = new File(datasetDir + "/thread-" + String.valueOf(i));
            if(!file.exists()) break;
            BufferedReader br = new BufferedReader(new FileReader(file));
            while((line = br.readLine()) != null) {
                bwOfThread.write(line + "\n");
            }
            br.close();
        }
        bwOfThread.flush(); bwOfThread.close();

        //combine rank data generated by different threads
//        BufferedWriter bwOfRank = new BufferedWriter((new FileWriter(new File("./data/kNNDist"))));
////        for(int i = 0; i < numThreads; i++) {
////            file = new File(datasetDir + "/thread-" + String.valueOf(i) + "-distance");
////            if(!file.exists()) break;
////            BufferedReader br = new BufferedReader(new FileReader(file));
////            while((line = br.readLine()) != null) {
////                bwOfRank.write(line + "\n");
////            }
////            br.close();
////            //file.delete();
////        }
////        bwOfRank.flush(); bwOfRank.close();

        //combine rank data generated by different threads
        for(int i = 0; i < numThreads; i++) {
            String tempPath = datasetDir + "/thread-" + String.valueOf(i) + "-threshold";
            file = new File(tempPath);
            if(!file.exists()) continue;
            //file.delete();
        }
    }
}

class SiameseDataThread extends Thread  {
    private int threadID;
    private int fileSize;
    private String datasetDir;
    private double trainRatio;
    private String dataType;

    public SiameseDataThread(int threadID, String datasetDir, double sampleRatio, String dataType, int fileSize) {
        this.fileSize = fileSize;
        this.threadID = threadID;
        this.datasetDir = datasetDir;
        this.trainRatio = sampleRatio;
        this.dataType = dataType;
    }

    public void run() {
        try {
            generateSiameseSamples();
            //root.print();
        }catch(Exception e) {
            e.printStackTrace();
        }
    }

    void generateSiameseSamples() throws IOException {
        Random random = new Random();
        BufferedReader p1Reader, p2Reader, thresholdReader;
        BufferedWriter trainWriter = new BufferedWriter(new FileWriter(new File("./data/trainingData-siamese-" + String.valueOf(threadID))));
        //format: P1, P2, distance, kNN distance of P1
        trainWriter.write("P1,P2,distance,cutoff\n");
        String[] lines = new String[2];
        Object[][] points = new Object[2][];

        double marker = 0;
        String file = datasetDir + "/thread-" + String.valueOf(threadID);
        p1Reader = new BufferedReader(new FileReader(new File(file)));
        thresholdReader = new BufferedReader(new FileReader(new File(file + "-threshold")));
        String threshold;
        while((lines[0] = p1Reader.readLine()) != null &&
                (threshold = thresholdReader.readLine()) != null) {
            marker++;
            if(marker % 100 == 0 && threadID == 0) {
                System.out.println(String.valueOf(Math.round(marker / fileSize * 100)) + "% points processed...");
            }
            if(random.nextDouble() < 0.8) continue;
            points[0] = Utils.getValuesFromLine(lines[0], " ", dataType);
            double thres = Double.parseDouble(threshold);
            for(int j = threadID; j < DataGenerator.numThreads; j++) {
                p2Reader = new BufferedReader(new FileReader(new File(datasetDir + "/thread-" + String.valueOf(j))));
                while((lines[1] = p2Reader.readLine()) != null) {
                    points[1] = Utils.getValuesFromLine(lines[1], " ", dataType);
                    //double sim = Utils.Utils.computeSimilarity(points[0], points[1], maxDist, "Euclidean", "staircase");
                    double dist = Utils.computeEuclideanDist(points[0], points[1]);
                    if(dist==0) continue;
                    if(random.nextDouble() < trainRatio || dist < thres){
                        trainWriter.write(lines[0] + "," + lines[1] + "," + String.valueOf(dist) + "," + threshold + "\n");
                        //trainWriter.write(lines[0] + "," + lines[1] + "," + String.valueOf(dist/thres) + "," + String.valueOf(1.0) + "\n");
                    }
                }
                p2Reader.close();
            }
        }
        p1Reader.close();
        trainWriter.flush(); trainWriter.close();
        //testWriter.flush(); testWriter.close();
    }
}

class TripletDataThread extends Thread  {
    private int threadID;
    private int fileSize;
    private String datasetDir;
    private double trainRatio;
    private String dataType;
    private double nonNeighborSampleRatio = 0.05;

    public TripletDataThread(int threadID, String datasetDir, double sampleRatio, String dataType, int fileSize) {
        this.fileSize = fileSize;
        this.threadID = threadID;
        this.datasetDir = datasetDir;
        this.trainRatio = sampleRatio;
        this.dataType = dataType;
    }

    public void run() {
        try {
            generateTripletSamples();
            //root.print();
        }catch(Exception e) {
            e.printStackTrace();
        }
    }

    void generateTripletSamples() throws IOException {
        Random random = new Random();
        BufferedReader p1Reader, p2Reader;
        BufferedWriter trainWriter = new BufferedWriter(new FileWriter(new File("./data/trainingData-triplet-" + String.valueOf(threadID))));
        //BufferedWriter testWriter = new BufferedWriter(new FileWriter(new File(path + "/validationData-" + String.valueOf(threadID) + ".csv")));
        trainWriter.write("anchor,positive,negative\n");
        //testWriter.write("P1,P2,distance,cutoff\n");
        String[] lines = new String[2];
        Object[][] points = new Object[2][];

        //iterates each file
        double marker = 0;
        String file = datasetDir + "/thread-" + String.valueOf(threadID);
        p1Reader = new BufferedReader(new FileReader(new File(file)));
        while((lines[0] = p1Reader.readLine()) != null) {
            marker++;
            if(marker % 100 == 0 && threadID == 0) {
                System.out.println(String.valueOf(Math.round(marker / fileSize * 100)) + "% points processed...");
            }
            if(random.nextDouble() < 0.8) continue;
            points[0] = Utils.getValuesFromLine(lines[0], " ", dataType);
            PriorityQueue rankQueue = new PriorityQueue(51,"ascending");
            Set<String> nonNeighbors = new HashSet<>();
            for(int j = threadID; j < DataGenerator.numThreads; j++) {
                p2Reader = new BufferedReader(new FileReader(new File(datasetDir + "/thread-" + String.valueOf(j))));
                while((lines[1] = p2Reader.readLine()) != null) {
                    points[1] = Utils.getValuesFromLine(lines[1], " ", dataType);
                    //double sim = Utils.Utils.computeSimilarity(points[0], points[1], maxDist, "Euclidean", "staircase");
                    double dist = Utils.computeEuclideanDist(points[0], points[1]);
                    if(dist==0) continue;
                    rankQueue.insert(dist, lines[1]);
                    if(random.nextDouble() < nonNeighborSampleRatio) {
                        nonNeighbors.add(lines[1]);
                    }
                }
                p2Reader.close();
            }
            List<String> kNNs = rankQueue.serialize();
            nonNeighbors.removeAll(kNNs);
            //write kNNs as an ordered list
//            for(int j = 0; j < kNNs.size(); j++) {
//                if(j == 0) trainWriter.write(lines[0] + ",");
//                if(j != kNNs.size() - 1) trainWriter.write( kNNs.get(j) + "#");
//                else trainWriter.write(kNNs.get(j) + "\n");
//            }
            //write kNNs as triplets: anchor, j-th, (j+1)-th, and
            //anchor, a neighbor, a non-neighbor
            for(int j = 0; j < kNNs.size(); j++) {
                if(j < kNNs.size() - 1)
                    trainWriter.write(lines[0] + "," + kNNs.get(j) + "," + kNNs.get(j+1) + "\n");
                else {
                    for(String nonNeighbor : nonNeighbors) {
                        trainWriter.write(lines[0] + "," + kNNs.get(j) + "," + nonNeighbor + "\n");
                    }
                }
            }
        }
        p1Reader.close();
        trainWriter.flush(); trainWriter.close();
        //testWriter.flush(); testWriter.close();
    }
}
